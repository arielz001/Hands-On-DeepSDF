{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4186ca0f",
   "metadata": {},
   "source": [
    "# Install libraries "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8c4a5a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu126"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1956805",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install matplotlib numpy mesh-to-sdf trimesh plyfile open3d"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9f0e5ee",
   "metadata": {},
   "source": [
    "# Clone the repository to get the data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5905ea9",
   "metadata": {},
   "source": [
    " To train a DeepSDF model, it is necessary to have a dataset consisting of a collection of 3D shapes. In this notebook, we will use any objects from internet. \n",
    "\n",
    " When we clone the repository, we can find a folder called `dataset`. This folder contains a collection of objects that we will use to train our model.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea663c86",
   "metadata": {},
   "outputs": [],
   "source": [
    "!git clone https://github.com/arielz001/Hands-On-DeepSDF.git"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f03d40f8",
   "metadata": {},
   "source": [
    "# Understanding SDF values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b658734c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "def example_sdf():\n",
    "    def circle_sdf(x, y, center, radius):\n",
    "        return np.sqrt((x - center[0])**2 + (y - center[1])**2) - radius\n",
    "\n",
    "    x = np.linspace(-150, 150, 400)\n",
    "    y = np.linspace(-150, 150, 400)\n",
    "    X, Y = np.meshgrid(x, y)\n",
    "\n",
    "    fig, ax = plt.subplots()\n",
    "    ax.set_title(\"Visualization SDF\")\n",
    "    ax.set_xlabel(\"X\")\n",
    "    ax.set_ylabel(\"Y\")\n",
    "    ax.set_aspect('equal')\n",
    "\n",
    "    center = [0, 0]\n",
    "    radius = 80\n",
    "    Z = circle_sdf(X, Y, center, radius)\n",
    "    im = ax.imshow(Z, extent=[x.min(), x.max(), y.min(), y.max()],\n",
    "                cmap='RdBu', origin='lower', vmin=-radius, vmax=radius)\n",
    "\n",
    "    cbar = plt.colorbar(im, ax=ax)\n",
    "    cbar.set_label('Signed Distance Function')\n",
    "\n",
    "    contour = ax.contour(X, Y, Z, levels=[0], colors='black', linewidths=2)\n",
    "\n",
    "    plt.show()\n",
    "    \n",
    "example_sdf()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81308cd6",
   "metadata": {},
   "source": [
    "# Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31a4b147",
   "metadata": {},
   "source": [
    "## Preprocessing data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3965f97c",
   "metadata": {},
   "source": [
    "##### Now we must create the sdf values for each obj in the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a61118c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from mesh_to_sdf import sample_sdf_near_surface\n",
    "\n",
    "import os\n",
    "import glob\n",
    "import trimesh\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "def generate_xyz_sdf(filename):\n",
    "    mesh = trimesh.load(os.path.abspath(filename),force='mesh')\n",
    "    xyz, sdf = sample_sdf_near_surface(mesh, number_of_points=15000)\n",
    "    return xyz, sdf\n",
    "\n",
    "def writeSDFToNPZ(xyz, sdfs, filename):\n",
    "    num_vert = len(xyz)\n",
    "    pos = []\n",
    "    neg = []\n",
    "\n",
    "    for i in range(num_vert):   # for each vertex in the shape\n",
    "        v = xyz[i]   # Point Position Value\n",
    "        s = sdfs[i]  # Signed Distance Function Value\n",
    "\n",
    "        if s > 0:\n",
    "            for j in range(3):\n",
    "                pos.append(v[j])     # remember that vertex have 3 coordinates\n",
    "            pos.append(s)            # adding the positive value\n",
    "\n",
    "        else:\n",
    "            for j in range(3):\n",
    "                neg.append(v[j])     # for each coordinate in the vertex\n",
    "            neg.append(s)            # adding the negative value\n",
    "\n",
    "\n",
    "    #========================================================================\n",
    "    # TODO:\n",
    "\n",
    "    # Save the values reshaping both 'pos' and 'neg' into arrays with 4 columns.\n",
    "    # The file will contain two named arrays: 'pos' and 'neg', each of shape (N, 4)\n",
    "    # Where N is the number of vertices in the shape.\n",
    "    # so you have to reshape the arrays following this order: array.reshape(-1, 4)\n",
    "    # ========================================================================\n",
    "    np.savez(filename, pos=None, neg=None)\n",
    "    \n",
    "    # ========================================================================\n",
    "\n",
    "\n",
    "def process(mesh_filepath, target_filepath):\n",
    "    xyz, sdfs = generate_xyz_sdf(mesh_filepath)\n",
    "    writeSDFToNPZ(xyz, sdfs, target_filepath)\n",
    "    \n",
    "\n",
    "\n",
    "target_path = f\"./processed_data\"\n",
    "\n",
    "os.makedirs(target_path, exist_ok=True)\n",
    "\n",
    "mesh_filenames = list(glob.iglob(\"dataset/\"  + \"*.obj\"))\n",
    "\n",
    "N = len(mesh_filenames)\n",
    "it = 0\n",
    "\n",
    "for mesh_filepath in mesh_filenames:\n",
    "\n",
    "    base_name = os.path.splitext(os.path.basename(mesh_filepath))[0]\n",
    "    target_filepath = os.path.join(target_path, base_name)\n",
    "    \n",
    "    print(f\"base_name: {base_name}\")\n",
    "    process(mesh_filepath, target_filepath)\n",
    "\n",
    "    it += 1\n",
    "    print(f\"Process finished directory: {it}/{N}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c17f137d",
   "metadata": {},
   "source": [
    "#### Shapenet type of dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1beca76",
   "metadata": {},
   "source": [
    "This class implements a custom PyTorch dataset that loads data from `.npz` files and generates balanced samples of positive and negative points.\n",
    "\n",
    "## How it works\n",
    "\n",
    "- Reads all `.npz` files from a given folder.\n",
    "- Each file contains two arrays: positive points (`pos`) and negative points (`neg`).\n",
    "- For each file, it takes a total of `you can define the quantity of points` points from each array.\n",
    "- If there are fewer than `num of points that you defined / 2`  of a type, it performs random sampling with replacement to complete the quota.\n",
    "- If there are more than `num of points that you defined / 2`  points, it takes a random continuous block of that size.\n",
    "- Concatenates both subsets to form the final sample.\n",
    "- Stores all loaded samples in an internal list.\n",
    "\n",
    "## Methods\n",
    "\n",
    "- `__getitem__(index)`: returns a tuple `(index, sample)` for the sample at the given index.\n",
    "- `__len__()`: returns the total number of samples (loaded `.npz` files).\n",
    "\n",
    "---\n",
    "\n",
    "This dataset is designed to facilitate training models that require balanced samples of positive and negative points from data stored in `.npz` files.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7723d8a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "\n",
    "import numpy as np\n",
    "import random\n",
    "from pathlib import Path\n",
    "\n",
    "class ShapeNet_Dataset(Dataset):\n",
    "    \n",
    "    def __init__(self, dataset_path):\n",
    "        global num_samples  \n",
    "        self.dataset = []\n",
    "        for file_name in sorted(Path(dataset_path).glob(\"*.npz\")):\n",
    "            \n",
    "\n",
    "            # TODO: create tensors with torch from numpy\n",
    "                # remember that npz have 2 arrays: pos and neg\n",
    "                # and the command is torch.from_numpy(array) \n",
    "                # and the numpy arrays are pos_tensor = npz['pos'] and neg_tensor = npz['neg']\n",
    "\n",
    "            npz = np.load(file_name)\n",
    "            pos_tensor = None\n",
    "            neg_tensor = None\n",
    "          \n",
    "\n",
    "            # TODO: set a value of the samples\n",
    "            num_samples = None\n",
    "\n",
    "            # split the sample into half\n",
    "            half = int(num_samples / 2)\n",
    "\n",
    "            pos_size = pos_tensor.shape[0]\n",
    "            neg_size = neg_tensor.shape[0]\n",
    "            \n",
    "            # if size of values is less than half\n",
    "            # then select random values from the values\n",
    "\n",
    "            # if size of values is greater than half\n",
    "            # then select the half from the values\n",
    "\n",
    "            if pos_size <= half:\n",
    "                random_pos = (torch.rand(half) * pos_tensor.shape[0]).long()\n",
    "                sample_pos = torch.index_select(pos_tensor, 0, random_pos)\n",
    "            else:\n",
    "                pos_start_ind = random.randint(0, pos_size - half)\n",
    "                sample_pos = pos_tensor[pos_start_ind : (pos_start_ind + half)]\n",
    "\n",
    "            if neg_size <= half:\n",
    "                random_neg = (torch.rand(half) * neg_tensor.shape[0]).long()\n",
    "                sample_neg = torch.index_select(neg_tensor, 0, random_neg)\n",
    "            else:\n",
    "                neg_start_ind = random.randint(0, neg_size - half)\n",
    "                sample_neg = neg_tensor[neg_start_ind : (neg_start_ind + half)]\n",
    "\n",
    "            samples = torch.cat([sample_pos, sample_neg], 0)\n",
    "            \n",
    "            self.dataset.append(samples)\n",
    "            \n",
    "    def __getitem__(self, index):\n",
    "        return index, self.dataset[index]\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ce991a5",
   "metadata": {},
   "source": [
    "# Define the model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b336361c",
   "metadata": {},
   "source": [
    "The following image shows the architecture of the DeepSDF model.\n",
    "\n",
    "<img src=\"./assets/network-arch.png\" alt=\"Architecture\" width=\"1200\"/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "599f7f3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class Decoder(nn.Module):\n",
    "    \n",
    "    # TODO: we have to define the sizes of the ouput layers following the last image\n",
    "    #       and in which layer is the latent vector again (in the middle?)\n",
    "    #       remember change the None values in the init function\n",
    "    \n",
    "    def __init__(\n",
    "        self,\n",
    "        latent_size=None,\n",
    "        dims=[None, None, None, None, None, None, None, None, None],  # not consider the first input because is added later\n",
    "        dropout=[0, 1, 2, 3, 4, 5, 6,7],\n",
    "        dropout_prob=0.2,\n",
    "        norm_layers=[0, 1, 2, 3, 4, 5, 6,7],\n",
    "        latent_in=[None],\n",
    "        weight_norm=True):\n",
    "\n",
    "        super(Decoder, self).__init__()\n",
    "        \n",
    "        # TODO: change None value adding the size of first input (note: None value is the first layer)\n",
    "        dims = [None]  + dims\n",
    "\n",
    "        self.num_layers = len(dims)\n",
    "        self.norm_layers = norm_layers\n",
    "        self.latent_in = latent_in\n",
    "        self.weight_norm = weight_norm\n",
    "\n",
    "        for layer in range(0, self.num_layers - 1):\n",
    "            if layer + 1 in latent_in:\n",
    "                out_dim = dims[layer + 1] - dims[0]\n",
    "            else:\n",
    "                out_dim = dims[layer + 1]\n",
    "\n",
    "            if weight_norm and layer in self.norm_layers:\n",
    "                setattr(\n",
    "                    self,\n",
    "                    \"lin\" + str(layer),\n",
    "                    nn.utils.weight_norm(nn.Linear(dims[layer], out_dim)),\n",
    "                )\n",
    "            else:\n",
    "                setattr(self, \"lin\" + str(layer), nn.Linear(dims[layer], out_dim))\n",
    "\n",
    "        self.relu = nn.ReLU()\n",
    "        self.dropout_prob = dropout_prob\n",
    "        self.dropout = dropout\n",
    "        self.th = nn.Tanh()\n",
    "\n",
    "    def forward(self, input):\n",
    "        x = input\n",
    "\n",
    "        for layer in range(0, self.num_layers - 1):\n",
    "            lin = getattr(self, \"lin\" + str(layer))\n",
    "            if layer in self.latent_in:\n",
    "                x = torch.cat([x, input], 1)\n",
    "           \n",
    "            x = lin(x)\n",
    "            \n",
    "            if layer < self.num_layers - 2:\n",
    "                x = self.relu(x)\n",
    "                if self.dropout is not None and layer in self.dropout:\n",
    "                    x = F.dropout(x, p=self.dropout_prob, training=self.training)\n",
    "\n",
    "        if hasattr(self, \"th\"):\n",
    "            x = self.th(x)\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c28f7b38",
   "metadata": {},
   "source": [
    "# Train the model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c210ac9",
   "metadata": {},
   "source": [
    "The following image shows the loss function\n",
    "\n",
    " $\\mathcal{L}(f_\\theta(z_i, x_j), s_j) = \\left| \\operatorname{clamp}_\\delta(f_\\theta(z_i, x_j)) - \\operatorname{clamp}_\\delta(s_j) \\right|$\n",
    "\n",
    "Set the clamp value\n",
    "\n",
    "$\\operatorname{clamp}(X, \\delta) := min(\\delta, max(-\\delta,x))$\n",
    "\n",
    "- in the original paper they use $\\delta = 0.1$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f163f2b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "import numpy as np\n",
    "import random\n",
    "import os\n",
    "\n",
    "def train_decoder(epochs = 1000,\n",
    "                batch_size=5,\n",
    "                lat_vecs_std = 0.01,\n",
    "                decoder_lr = 0.0005,\n",
    "                lat_vecs_lr = 0.001,\n",
    "                train_data_path = \"./processed_data\",\n",
    "                checkpoint_save_path = \"./checkpoints/\"):\n",
    "    \n",
    "    os.makedirs(checkpoint_save_path, exist_ok=True)\n",
    "    # ------------ set random seed ------------\n",
    "\n",
    "    np.random.seed(42)\n",
    "    torch.manual_seed(42)\n",
    "    random.seed(42)\n",
    "\n",
    "    # ------------ setting device on GPU if available, else CPU ------------\n",
    "\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    print('Using device:', device)\n",
    "\n",
    "    # ------------ load dataset ------------set parameters\n",
    "\n",
    "    train_dataset = ShapeNet_Dataset(train_data_path) # sdf values and vertex coordinates (npz file)\n",
    "    torch_train = DataLoader(train_dataset,shuffle=True, batch_size=batch_size, num_workers=1)\n",
    "\n",
    "    # ------------ load auto decoder model ------------\n",
    "    \n",
    "    SDF_autodecoder = Decoder().to(device)\n",
    "\n",
    "    # ------------ set training parameters ------------\n",
    "\n",
    "    # initializa latent vectors\n",
    "    lat_vecs = torch.nn.Embedding(len(train_dataset), 256, max_norm=1.0).cuda()\n",
    "    torch.nn.init.normal_(lat_vecs.weight.data, 0.0, lat_vecs_std)\n",
    "\n",
    "    # set optimizer\n",
    "    optimizer_all = torch.optim.Adam(\n",
    "                    [{\"params\": SDF_autodecoder.parameters(),\n",
    "                    \"lr\": decoder_lr},\n",
    "                    {\"params\": lat_vecs.parameters(),\n",
    "                    \"lr\": lat_vecs_lr}])\n",
    "    \n",
    "    # loss function\n",
    "    loss_l1 = torch.nn.L1Loss(reduction=\"sum\")\n",
    "\n",
    "    # other parameters\n",
    "\n",
    "    # ===================================\n",
    "    # TODO: Set the delta value\n",
    "    delta = None\n",
    "    delta_min, delta_max = -delta, delta # clamp\n",
    "    # ==========================================\n",
    "\n",
    "\n",
    "\n",
    "    # ------------ training process ------------ \n",
    "\n",
    "    print(\"---- start training ----\")\n",
    "    loss_log = []\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        \n",
    "        SDF_autodecoder.train()\n",
    "\n",
    "        losses = []\n",
    "        \n",
    "        for index, train_data in torch_train:\n",
    "            \n",
    "            train_data = train_data.reshape(-1,4).cuda()\n",
    "            num_sdf_samples = train_data.shape[0]\n",
    "            train_data.requires_grad = False\n",
    "\n",
    "            xyz = train_data[:, 0:3]\n",
    "            sdf_gt = train_data[:, 3].unsqueeze(1)\n",
    "\n",
    "            # ========================================================================\n",
    "            # TODO: Calculate the loss Function\n",
    "            # torch.clamp() receive 3 parameters, the value, min threshold and max threshold\n",
    "            sdf_gt = torch.clamp(sdf_gt, None, None)\n",
    "            # ========================================================================\n",
    "\n",
    "\n",
    "            optimizer_all.zero_grad()\n",
    "\n",
    "            # concatenate latent vector and xyz query\n",
    "            indices = index.cuda().unsqueeze(-1).repeat(1, num_samples).view(-1)\n",
    "            batch_vecs = lat_vecs(indices)\n",
    "            input = torch.cat([batch_vecs, xyz], dim=1)\n",
    "\n",
    "            # NN optimization\n",
    "            pred_sdf = SDF_autodecoder(input)\n",
    "\n",
    "\n",
    "            # ========================================================================\n",
    "            # TODO: Calculate the loss Function\n",
    "            # torch.clamp() receive 3 parameters, the value, min threshold and max threshold\n",
    "\n",
    "            pred_sdf = torch.clamp(pred_sdf, None, None)\n",
    "            real_sdf = sdf_gt.cuda()\n",
    "            loss_function = loss_l1(None, None)\n",
    "            loss = loss_function / num_sdf_samples\n",
    "\n",
    "            # ========================================================================\n",
    "\n",
    "            loss.backward()\n",
    "            losses.append(loss.data.mean().cpu())\n",
    "\n",
    "            optimizer_all.step()\n",
    "            \n",
    "        # Print batch loss\n",
    "        epoch_loss = np.mean(losses)\n",
    "        loss_log.append(epoch_loss)\n",
    "        print(f'epoch: {epoch+1} / {epoch} | Loss: {epoch_loss:.5f}')\n",
    "        \n",
    "        torch.save({\n",
    "                'epoch': epoch,\n",
    "                'model': SDF_autodecoder.state_dict(),\n",
    "                'latent_vectors': lat_vecs.state_dict(),\n",
    "                'optimizer': optimizer_all.state_dict(),\n",
    "                'loss_log': loss_log,\n",
    "                # }, checkpoint_save_path + str(epoch+1) + \".pt\")\n",
    "                }, checkpoint_save_path  + \"trained_model_1.pt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "168a5595",
   "metadata": {},
   "source": [
    "### TODO: SET PARAMETERS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f59fa9a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: SET PARAMETERS\n",
    "train_decoder(epochs = None,\n",
    "                    batch_size=None,\n",
    "                    lat_vecs_std = 0.01,\n",
    "                    decoder_lr = None,\n",
    "                    lat_vecs_lr = None)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbceed6d",
   "metadata": {},
   "source": [
    "# Reconstruct mesh from a latent code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06b14f0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "import numpy as np\n",
    "import plyfile\n",
    "import skimage.measure\n",
    "\n",
    "# Learn the latent code for the test model\n",
    "def reconstruct_latent(decoder, \n",
    "                       sdf_data, \n",
    "                       iterations = 800,\n",
    "                       init_std = 0.01, \n",
    "                       lr = 5e-4):\n",
    "\n",
    "    # parameters\n",
    "    latent_size = 256\n",
    "    num_samples = num_samples  # this is the same as the number of points in the shapenet dataset class definition \n",
    "\n",
    "    # RANDOM LATENT VECTOR\n",
    "\n",
    "    latent = torch.rand(1, latent_size).normal_(mean=0, std=init_std).cuda()\n",
    "    latent.requires_grad = True\n",
    "\n",
    "    # set optimizer and loss\n",
    "    optimizer = torch.optim.Adam([latent], lr=lr)\n",
    "    loss_l1 = torch.nn.L1Loss()\n",
    "    delta_min, delta_max = -0.1, 0.1 # clamp\n",
    "\n",
    "    for it in range(iterations):\n",
    "        \n",
    "        decoder.eval()\n",
    "\n",
    "        xyz = sdf_data.cuda()[:, 0:3]\n",
    "        sdf_gt = sdf_data.cuda()[:, 3].unsqueeze(1)\n",
    "        sdf_gt = torch.clamp(sdf_gt, delta_min, delta_max)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        latent_inputs = latent.expand(num_samples, -1)\n",
    "        inputs = torch.cat([latent_inputs, xyz], 1)\n",
    "        pred_sdf = decoder(inputs)\n",
    "        pred_sdf = torch.clamp(pred_sdf, delta_min, delta_max)\n",
    "\n",
    "        loss = loss_l1(pred_sdf, sdf_gt)\n",
    "        loss += 1e-4 * torch.mean(latent.pow(2)) # L2 regularization\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        loss_num = loss.cpu().data.numpy()\n",
    "        print('[%d/%d] Loss: %.5f' % (it+1, iterations, loss_num))\n",
    "\n",
    "    return latent\n",
    "\n",
    "# Predict SDF with the latent code and trained decoder\n",
    "def decode_sdf(decoder, latent_vector, queries):\n",
    "    num_samples = queries.shape[0]\n",
    "    latent_repeat = latent_vector.expand(num_samples, -1)\n",
    "    inputs = torch.cat([latent_repeat, queries.cuda()], 1)\n",
    "    sdf = decoder(inputs)\n",
    "    return sdf\n",
    "\n",
    "\n",
    "def convert_sdf_samples_to_obj(\n",
    "    pytorch_3d_sdf_tensor,\n",
    "    voxel_grid_origin,\n",
    "    voxel_size,\n",
    "    obj_filename_out):\n",
    "    \"\"\"\n",
    "    Convert sdf samples to .obj\n",
    "\n",
    "    :param pytorch_3d_sdf_tensor: a torch.FloatTensor of shape (n,n,n)\n",
    "    :param voxel_grid_origin: list of three floats: the origin of the voxel grid (x, y, z)\n",
    "    :param voxel_size: float, size of each voxel\n",
    "    :param obj_filename_out: string, path to save the .obj file\n",
    "    \"\"\"\n",
    "\n",
    "    numpy_3d_sdf_tensor = pytorch_3d_sdf_tensor.numpy()\n",
    "\n",
    "    verts, faces, normals, values = skimage.measure.marching_cubes(\n",
    "        numpy_3d_sdf_tensor, level=0.0, spacing=[voxel_size] * 3\n",
    "    )\n",
    "\n",
    "    mesh_points = np.zeros_like(verts)\n",
    "    mesh_points[:, 0] = voxel_grid_origin[0] + verts[:, 0]\n",
    "    mesh_points[:, 1] = voxel_grid_origin[1] + verts[:, 1]\n",
    "    mesh_points[:, 2] = voxel_grid_origin[2] + verts[:, 2]\n",
    "\n",
    "    with open(obj_filename_out, 'w') as f:\n",
    "        for v in mesh_points:\n",
    "            f.write(f'v {v[0]} {v[1]} {v[2]}\\n')\n",
    "        for face in faces:\n",
    "            # OBJ uses 1-based indexing\n",
    "            f.write(f'f {face[0]+1} {face[1]+1} {face[2]+1}\\n')\n",
    "\n",
    "\n",
    "\n",
    "def create_mesh(filename, \n",
    "                decoder, \n",
    "                latent_vec,\n",
    "                N=128, \n",
    "                max_batch=16 ** 3):\n",
    " \n",
    "    decoder.eval()\n",
    "\n",
    "    # NOTE: the voxel_origin is actually the (bottom, left, down) corner, not the middle\n",
    "    voxel_origin = [-1, -1, -1]\n",
    "    voxel_size = 2.0 / (N - 1)\n",
    "\n",
    "    overall_index = torch.arange(0, N ** 3, 1, out=torch.LongTensor())\n",
    "    samples = torch.zeros(N ** 3, 4)\n",
    "\n",
    "    # transform first 3 columns\n",
    "    # to be the x, y, z index\n",
    "    samples[:, 2] = overall_index % N\n",
    "    samples[:, 1] = (overall_index.long() / N) % N\n",
    "    samples[:, 0] = ((overall_index.long() / N) / N) % N\n",
    "\n",
    "    # transform first 3 columns\n",
    "    # to be the x, y, z coordinate\n",
    "    samples[:, 0] = (samples[:, 0] * voxel_size) + voxel_origin[2]\n",
    "    samples[:, 1] = (samples[:, 1] * voxel_size) + voxel_origin[1]\n",
    "    samples[:, 2] = (samples[:, 2] * voxel_size) + voxel_origin[0]\n",
    "\n",
    "    num_samples = N ** 3\n",
    "\n",
    "    samples.requires_grad = False\n",
    "\n",
    "    head = 0\n",
    "\n",
    "    while head < num_samples:\n",
    "        sample_subset = samples[head : min(head + max_batch, num_samples), 0:3]#.cuda()\n",
    "        samples[head : min(head + max_batch, num_samples), 3] = (\n",
    "            decode_sdf(decoder, latent_vec, sample_subset)\n",
    "            .squeeze(1)\n",
    "            .detach()\n",
    "            .cpu()\n",
    "        )\n",
    "        head += max_batch\n",
    "\n",
    "    sdf_values = samples[:, 3]\n",
    "    sdf_values = sdf_values.reshape(N, N, N)\n",
    "\n",
    "    convert_sdf_samples_to_obj(sdf_values, \n",
    "                               voxel_grid_origin=[0.0, 0.0, 0.0], \n",
    "                               voxel_size=0.01, \n",
    "                               obj_filename_out=filename+'.obj')\n",
    "\n",
    "\n",
    "def reconstruct(test_sample,\n",
    "                decoder,\n",
    "                filename,\n",
    "                lat_iteration,\n",
    "                lat_init_std = 0.01, \n",
    "                lat_lr = 5e-4,\n",
    "                N=128, \n",
    "                max_batch=16 ** 3):\n",
    "\n",
    "    # pass the test model to decoder\n",
    "    _, test_sdf_data = test_sample\n",
    "\n",
    "    print(\"---- Fitting latent vector ----\")\n",
    "    latent_vector = reconstruct_latent(decoder, \n",
    "                                       test_sdf_data, \n",
    "                                       iterations = lat_iteration,\n",
    "                                       init_std = lat_init_std, \n",
    "                                       lr = lat_lr)\n",
    "\n",
    "    print(\"---- Reconstructing mesh ----\")\n",
    "    print(\" This could take a while \")\n",
    "    \n",
    "    create_mesh(filename, \n",
    "                decoder,\n",
    "                latent_vector,\n",
    "                N=N, \n",
    "                max_batch=max_batch)\n",
    "    \n",
    "    print(\"Mesh saved to \" + filename + \".obj\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf69b44d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "\n",
    "# ------------ setting device on GPU if available, else CPU ------------\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print('Using device:', device)\n",
    "\n",
    "# ------------ load some samples ------------\n",
    "train_data_path = \"./processed_data\"\n",
    "train_dataset = ShapeNet_Dataset(train_data_path)\n",
    "\n",
    "# ------------ load decoder ------------\n",
    "decoder = Decoder().to(device)\n",
    "checkpoint = torch.load(\"./checkpoints/trained_model_1.pt\", weights_only=False)\n",
    "decoder.load_state_dict(checkpoint[\"model\"])\n",
    "\n",
    "# ------------ reconstruction ------------\n",
    "reconstruction_path = \"./reconstruction\"\n",
    "os.makedirs(reconstruction_path, exist_ok=True)\n",
    "\n",
    "obj_to_reconstruct_idx = 0\n",
    "train_sample = train_dataset[obj_to_reconstruct_idx]\n",
    "\n",
    "filename = f\"{reconstruction_path}/example_\" + str(obj_to_reconstruct_idx)\n",
    "\n",
    "# ========================================================================\n",
    "# TODO: SET PARAMETERS\n",
    "# ========================================================================\n",
    "reconstruct(train_sample,\n",
    "            decoder,\n",
    "            filename,\n",
    "            lat_iteration=None,\n",
    "            lat_init_std = 0.01, \n",
    "            lat_lr = None,\n",
    "            N=256, \n",
    "            max_batch=32 ** 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "476c93f3",
   "metadata": {},
   "source": [
    "#### Visualize the decoded shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a2072b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import trimesh \n",
    "\n",
    "meshes_reconstructed = os.listdir('./reconstruction')\n",
    "mesh = os.path.join('./reconstruction', meshes_reconstructed[0])\n",
    "mesh = trimesh.load(mesh)\n",
    "mesh.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2ade97d",
   "metadata": {},
   "source": [
    "# shape completion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "593324c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_partial_pointcloud(mesh):\n",
    "\n",
    "    samples = np.array(trimesh.sample.sample_surface(mesh, 10000)[0])\n",
    "\n",
    "    t = [0.5, 1.0 , 1.0]\n",
    "    v_min, v_max = mesh.bounds\n",
    "\n",
    "    for i in range(3):\n",
    "        t_max = v_min[i] + t[i] * (v_max[i] - v_min[i])\n",
    "        samples = samples[samples[:, i] < t_max]\n",
    "    \n",
    "    return samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "e313f9a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = os.listdir('./dataset')\n",
    "meshes_to_completion = [f for f in data if f.endswith('.obj')]\n",
    "object_path = os.path.join('./dataset', meshes_to_completion[2])\n",
    "mesh = trimesh.load(object_path)\n",
    "partial_pc = generate_partial_pointcloud(mesh=mesh)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "b9013053",
   "metadata": {},
   "outputs": [],
   "source": [
    "import open3d as o3d\n",
    "\n",
    "pcd = o3d.geometry.PointCloud()\n",
    "pcd.points = o3d.utility.Vector3dVector(partial_pc)\n",
    "o3d.visualization.draw_geometries([pcd])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a898b1da",
   "metadata": {},
   "source": [
    "### infer a new latent code from the shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8414302c",
   "metadata": {},
   "outputs": [],
   "source": [
    "points = torch.tensor(partial_pc, dtype=torch.float32)\n",
    "\n",
    "xyz, sdf = sample_sdf_near_surface(mesh, number_of_points=15000)\n",
    "points = torch.tensor(xyz, dtype=torch.float32)\n",
    "sdf_values = torch.tensor(sdf, dtype=torch.float32).unsqueeze(1)\n",
    "points_sdf = torch.cat([points, sdf_values], dim=1)\n",
    "\n",
    "sample = (None, points_sdf)\n",
    "\n",
    "\n",
    "# TODO: SET PARAMETERS FOR RECONSTRUCTION\n",
    "reconstruct(sample,\n",
    "            decoder,\n",
    "            './reconstruction_from_partial/reconstructed_mesh',\n",
    "            lat_iteration=None,\n",
    "            lat_init_std=0.01,\n",
    "            lat_lr=None,\n",
    "            N=256,\n",
    "            max_batch=32**3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b4ca89c",
   "metadata": {},
   "outputs": [],
   "source": [
    "mesh = trimesh.load('./output_filename.obj')\n",
    "mesh.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "handson",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
